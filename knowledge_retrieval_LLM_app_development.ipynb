{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Retrieval Chatbot LLM App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "import os\n",
    "import argparse\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch environmental variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to process the input text file, remove empty lines and unneeded formatting marks\n",
    "def process_input_text(input_file_path):\n",
    "    '''\n",
    "    process_input_text() helper function takes the text file as an argument and\n",
    "    removes empty lines and non-essential characters. The output is saved\n",
    "    in a temporary directory.\n",
    "    \n",
    "    Parameters:\n",
    "        input_file_path (str): path to the input text file\n",
    "    \n",
    "    Returns:\n",
    "        processed temporary text file path saved in temp/\n",
    "    '''\n",
    "    \n",
    "    # create a temporary file in the same directory as input file\n",
    "    temp_dir = os.path.join(os.path.dirname(input_file_path), \"temp\")\n",
    "    os.makedirs(temp_dir, exist_ok = True)\n",
    "    \n",
    "    temp_file = tempfile.NamedTemporaryFile(mode = 'w', delete = False, dir = temp_dir, encoding = 'UTF-8')\n",
    "    \n",
    "    try:\n",
    "        # Read the contents of the file\n",
    "        with open(input_file_path, 'r', encoding = 'UTF-8') as input_file:\n",
    "            lines = input_file.readlines()\n",
    "\n",
    "        # Remove empty lines\n",
    "        non_empty_lines = [line.strip() for line in lines if line.strip() and not all(char in {'-', '_'} for char in line.strip())]\n",
    "\n",
    "        # write processed text to the temporary file\n",
    "        temp_file.write('\\n'.join(non_empty_lines))\n",
    "    finally:\n",
    "        # close the temporary file\n",
    "        temp_file.close()\n",
    "        \n",
    "    # get the path of the temporary file\n",
    "    temp_file_path = temp_file.name\n",
    "    \n",
    "    return temp_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to ask questions to LLM chain\n",
    "def answer_question(q, chain):\n",
    "    '''\n",
    "    answer_question() is a helper function to ask a single question from\n",
    "    a LLM chain\n",
    "    \n",
    "    Parameters:\n",
    "        q (str): user's question\n",
    "        crc (langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain):\n",
    "            ConversationalRetrievalChain object from Langchain\n",
    "    \n",
    "    '''\n",
    "    result = chain.invoke({'question': q})\n",
    "    return result['answer']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text_file = \"Software_Engineering_Practices.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process input file\n",
    "processed_text_file_path = process_input_text(input_text_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(processed_text_file_path, encoding = 'UTF-8') # need encoding specified\n",
    "data = loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='PHC Imaging\\nTechnical Operating Procedure\\nSoftware Engineering Practices for Personalized HealthCare Imaging Algorithms\\n1. Purpose\\nGood software engineering practice adherence is required for compliance with Roche Quality Management System policies. This will ensure that our code development is uniform and well documented to keep us within regulations, allowing us to support development work on regulated systems and devices.\\nThe purpose of this document is to provide the teams responsible for the development of Medical Imaging Algorithms, with high-level principles and concepts making up the software engineering practices in the Personalized HealthCare (PHC) Imaging group.\\nAs different subteams within the PHC Imaging group have different processes, coding standards and tools that they may use, this document is intended to serve as a high-level and an overarching Technical Operating Procedure (TOP) across the PHC imaging subteams. Individual product teams may have more specific coding standards, guidelines, processes tailored to their product areas (not documented in this TOP).\\n2. Scope and out of scope\\nThis document applies to all rule based and Machine Learning (ML) based algorithms delivered within the PHC Imaging group. Within ML based algorithms/models, the scope of this document is limited to locked models (and not continuously learning models).\\n1. In Scope\\n* Rule-based and ML based algorithm development life cycle\\n* High-level guidelines for coding standards\\n* High-level guidelines on documentation associated with each algorithm\\n* Version control process\\n* Peer review process\\n* Roles and responsibilities\\n2. Out of Scope\\n* Other procedures and methodologies applied in Roche CSV or PMM\\n* Coding standards/guidelines tailored to specific product teams\\n* As the algorithms are hosted as gears in Apollo-Flywheel Global Imaging Platform (GIP), additional PHC Informatics (IX) processes-practices will apply to these algorithms, these PHC IX practices are not described in this document\\n* Testing Management Procedure\\n* Change Management Procedure\\n* Release Management Procedure\\n3. Definitions\\nThe following terms and abbreviations are used in this document:\\nTerm: \\tDefinition\\nAlgorithm/Model: \\tFor the scope of this document, an algorithm/model is the application developed by PHC imaging group to analyze medical images\\nCNN: \\tConvolutional Neural Networks\\nCSV: \\tComputer System Validation\\nRule-based algorithms: \\tThese are rule based deterministic algorithms which produce pre-defined outcomes that are based on a set of certain rules\\nDS: \\tData Science\\nGIP/Flywheel: \\tPHC Informatics’ Flywheel based Global Imaging Platform (This is a part of the PHC Informatics Apollo platform)\\nML based algorithms: \\tMachine Learning based probabilistic algorithms are algorithms that define their own set of rules that are based on data outputs\\nLocked Model: \\tSynonymous with “Locked algorithm”. A model that was developed through data-based AI methods, but does not update itself in real time (although supplemental updates can be made to the software on a regular basis).\\nPHC: \\tPersonalized HealthCare\\nPHC Imaging Group: \\tFor the scope of this document, the following PHC Imaging teams together will constitute the PHC Imaging group - Oncology Imaging team, Ophthalmology Imaging team, Neuroscience Imaging team. Note - Digital Pathology (DP) Imaging team has separate processes in place and are out-of-scope of this TOP\\nPHC IX: \\tPersonalized HealthCare Informatics\\nProduct teams: \\tFor the scope of this document, product teams include - Oncology Imaging Products team and Ophthalmology Imaging Products team (NOTE - Neuroscience imaging team currently does not have Neuroscience product teams)\\nProduct Candidate: \\tAn algorithm that is planned for imminent deployment as a product (to be used in GxP scenarios e.g. in the conduct of a clinical trial, OR being developed as a Software as a Medical Device)\\nProduct: \\tAn algorithm that is being used in GxP scenarios e.g. in the conduct of a clinical trial, OR as a Software as a Medical Device\\nPMM: \\tProject Management Methodology\\nSaMD: \\tSoftware as a Medical Device\\nTOP: \\tTechnical Operating Procedure\\n4. Algorithm development life cycle\\n4.1 Rule-based algorithm development life cycle\\nRule-based algorithms developed within the PHC imaging group should follow the above development life cycle; details on each phase and step are described below (more information on development/experimental, qualification and deployment phase is detailed in the “Life Cycle management” subsection below)\\nInitialization & Preparation Phase\\na. Business case evaluation: In this step, the team will identify the unmet need (objective & requirement) in clinical development and/or practice, and translate it to an algorithm development problem.\\nDevelopment/Experimental Phase\\nb (i) Design and b (ii) Coding/Implementation: This step will involve evaluating the algorithm requirements and determining the rules; developing a high-level (aka business logic) as well as a low-level-design (aka programming logic) for the algorithm. The output of this step will be a high-quality working implementation of the algorithm ready for testing.\\nc. Testing: This step will involve unit and integration testing of the algorithm.\\nQualification Phase\\nd. Algorithm release (as a Flywheel gear): This step will involve converting the algorithm into a Flywheel gear.\\ne. Troubleshooting/Qualification: This step will involve any troubleshooting activities needed. It will also involve performing Computer System Validation, Technical Validation/Analytical Validation.\\nDeployment Phase\\nf. Algorithm deployment (CSV/SaMD) This step will involve deployment of the algorithm as a product (this could entail external deployments as well - e.g at the Independent Review Facility (IRF))\\ng. Algorithm operations and Maintenance Once the algorithm has been released for use it is subject to Change Management processes in the same manner as any other validated system. A GxP compliance Change Management process will be followed.\\n4.2 Machine Learning (ML) based algorithm development life cycle\\nML based algorithms developed within the PHC imaging group should follow the above development life cycle; details on each phase and step are described below (more information on development/experimental, qualification and deployment phase is detailed in the “Life Cycle Management” subsection below)\\nInitialization and Preparation Phase:\\n1. Business case evaluation: In this step, the team will identify the unmet need (objective & requirement) in clinical development and/or practice, and translate it to a modeling problem.\\n2. Data strategy and data acquisition: In this step, the team will identify the types and the amount of data to support the algorithm development to answer the business questions identified in step a; this step will also involve collecting or acquiring the identified datasets, data curation, databasing and determining if additional annotations or labels are needed.\\nDevelopment/Experimental Phase:\\n3. (i) Pipeline design and specification\\n* Planning: In this sub-step, the team will design and specify the pipeline to take the data source prepared in step b as input, to address the question listed in step a. The team would also ensure the following -\\n* Data quality and systematic biases in the datasets are adequately assessed.\\n* Training, validation and holdout/test datasets are prespecified. The split needs to avoid any potential information leakage.\\n* Performance measurement is prespecified preferably including how the uncertainty is assessed.\\n(ii) Data preprocessing: preprocessing pipeline will be developed in this sub-step\\n(iii) Algorithm training: certain algorithm class for instance Convolutional Neural Networks (CNN) is experimented in this sub-step\\n(iv) Algorithm evaluation: The most promising algorithm based on validation is tested for the performance on the independent test dataset (also called holdout dataset).\\nQualification Phase:\\nd. Algorithm release (as a Flywheel gear) This step will involve converting the algorithm into a Flywheel gear.\\ne. Troubleshooting/Qualification This step will involve any troubleshooting activities needed. It will also involve performing Computer System Validation, Technical Validation/Analytical Validation (including characterization of the algorithm)\\nDeployment Phase\\nf. Algorithm deployment (CSV/SaMD) This step will involve deployment of the algorithm as a product (this could entail external deployments as well - e.g at the Independent Review Facility (IRF))\\ng. Algorithm operations and Maintenance Once the algorithm has been released for use it is subject to Change Management processes in the same manner as any other validated system. A GxP compliance Change Management process will be followed.\\n4.3 Life Cycle Management\\n- Both rule-based and ML based algorithm development life-cycle typically follow an iterative process prior to the Qualification Phase, and therefore may apply Agile development principles (i.e., algorithm requirements may be managed and incorporated into, over multiple iterations)\\n- Currently, the development life-cycle is divided into 4 phases - Initialization & preparation, development/experimental phase, qualification phase and deployment phase and the phase gates to go from one phase to the next are shown in the figure below\\n- Initialization & preparation - As described in the sub-section above, this phase will entail identifying the unmet need (objective & requirement) in clinical development and/or practice, and translate it to a modeling problem. This phase will also include data strategy and data acquisition for ML based algorithms\\n- Development/Experimental phase - This phase will entail algorithm development before converting it into a Flywheel gear.\\n- Qualification phase - Qualification phase will begin as the algorithms are converted into Flywheel gears.\\n- This phase will include Flywheel gear algorithms that are also being utilized in non-GxP scenarios/for internal decision making (i.e research and development purposes) or are product candidates (i.e planned for imminent deployment as a product)\\n- In this phase, product candidates will subjected to the Computer System Validated (CSV) process to be compliant with 21 Code of Federal Regulations (CFR) Part 11, or other similar regulations (e.g. European Union’s Annex 11) before they are utilized in GxP use cases (i.e. use of the algorithm/gear as a part of the Clinical trial)\\n- For product candidates that are planned to be developed and deployed as SaMD, appropriate processes will be triggered to ensure compliance with ISO 13485\\n- Deployment phase - This phase will entail a algorithm that is being used in GxP scenarios e.g. in the conduct of a clinical trial, OR as a Software as a Medical Device.\\nWithin the above rule based/ML based algorithm development frameworks, for each algorithm, product teams are expected to also adhere to the following standards (described in the sections below) around these focus areas - coding, documentation associated with each algorithm, version control, peer review process and roles and responsibilities. The expected standards around each of these focus areas are different between development/experimental phase and qualification/deployment phase.\\n5. Coding Standards\\na. Why Coding Standards\\nCoding standards are a series of recommendations and mandates for a specific programming language that determines the programming style, procedures, methods, for various aspects of the program written in that language. They are a very critical attribute of algorithm development.\\nA coding standard ensures that all developers writing the code in a particular language write according to the guidelines specified. This provides consistency in the code, makes the code easy to understand, debug and maintain.\\nAdvantages of Coding Standards:\\n* Consistency\\n* Quality of the system\\n* Increases efficiency\\n* Minimize the risk of project failure\\n* Reduces complexity\\n* Maintenance becomes easy\\n* Correction of bugs\\n* A comprehensive view\\n* Cost saving\\nb. High-level Coding Standards\\nAppropriate coding standards for algorithm development ensure that the developer creates\\nthe computer programs to implement the rule based/ML-based algorithm that is adequately managed, modularized, and well commented. Also it ensures to improve on such dimensions as readability, quality, scalability and maintainability of the code.\\n#1\\nModularize your design\\n* Follow DRY principle:  “Do not Repeat Yourself” and aim to automate repetitive tasks.\\n#2\\nWrite readable code\\n* Use understandable naming conventions for identifiers.\\n* Keep your line length 80 characters or less\\n* Consistently indent your code\\n* Use whitespaces around operators and assignment\\n#3\\nComment your code clearly*\\n* Ensure that you do not comment on your code unnecessarily.\\n* Limit Comment Length.\\n*Here by comment, we mean the inline/single-line/multi-line comments. Recommendations on the stand-alone document files and docstrings are in the next section “Documentation”\\n#4\\nUse virtual environments\\n* This will avoid any library clashes, since different projects may need different versions of a certain library.\\nFor algorithms that are promoted to qualification/deployment phase, they should also adhere to the following coding standard\\n#5\\nCode Refactoring: in this context the term is formally defined as a process that involves editing and cleaning up previously written software code without changing the function of the code at all. The basic purpose of code refactoring is to make the code more efficient and maintainable.\\n6. Documentation\\nDocumentation is one of the key focus areas in good software engineering practices for rule based/ML based algorithm development to ensure ease of peer review, reproducibility of results and regulatory compliance (for algorithms that are developed into SaMD/GxP use products).\\nDuring the development/experimental phase, each algorithm should adhere to the following documentation standards:\\n* Documentation associated with the algorithm should be stored in the README file of the version control platform\\n* Documentation should consist of information on the following attributes: \\u200b\\u200bhow the algorithm was created, the training and the test data characteristics, what alternatives were considered, algorithm evaluation strategies, information on algorithm performance, associated analysis plan etc. along with author’s name and UNIX ID\\n* Within the code, Python documentation string “docstring” (or similar functions) to be used to add information around the class, module, function or method\\nFor algorithms that are promoted to qualification/deployment phase - Product teams should also consider the use of documentation automation tools like Sphinx, Pydoc, etc. Use of these automated algorithm documentation tools help ensure consistency, accuracy, improve collaboration, save time and money and could also help ensure regulatory compliance as product candidates are converted to products.\\n7. Version Control\\nFor development/experimental as well as qualification/deployment phase algorithms, product teams should use only enterprise validated code hosting and code versioning platforms for version control. Currently only GitLab (code.roche.com) and GitHub (github.roche.com) platforms are enterprise validated for code storing-code versioning.\\nNote: For algorithms that are being promoted to qualification phase (to be hosted as gears within Flywheel), the PHC IX team will host the algorithm’s code in the PHC IX designated code repository.\\n8. Peer Review\\nFor development/experimental phase algorithms, peer review of the code is required in case of collaborative development with other Data Scientists in the same product team.\\n* Pull Request (PR) could be submitted after modular enhancement/feature implementation, debugging and testing\\n* PR to be initiated frequently and for short lines of code (e.g <2000 lines) to get immediate feedback and prevent code fatigue by reviewer\\nFor algorithms that are promoted to qualification/deployment phase, a peer review process is required before the algorithm can be converted into a gear within Flywheel. The peer reviewer will be responsible for code review, and for ML-based algorithms, verifying the model performance and reproducibility of results. For demonstrating compliance with this requirement, the reviewer will follow the following process\\n* Check-out the code from the version control platform\\n* Add a note detailing the review process, summarizing any observations and findings, and confirming the completion of the peer review with the completion date, along with their name and UNIX ID in the README file\\n* Check-in the code back into the version control platform\\n9. Roles and Responsibilities\\nThis section provides additional details on roles and responsibilities in the context of rule based/ML based algorithm development life-cycle\\nAlgorithm Owner\\n* Responsible for Go/No-go decision to promote the algorithm from experimental phase to qualification phase with input from the peer-reviewer\\n* Responsible for market, business case and competitive analysis\\n* Responsible for long and short term product roadmap\\n* This would typically be the Integrated Solutions Product Lead (ISPL) for that algorithms’ therapeutic area (unless specified otherwise)\\nAlgorithm Developer\\n* Responsible for developing the algorithm as per coding standards\\n* Responsible for end-to-end algorithm design and communication\\n* Responsible for verification (e.g. - unit and integration testing) of each iteration outcome\\n* Responsible for documentation associated with each algorithm that they developed\\n* Responsible for facilitating peer review (applicability of this peer review process is defined in the preceding “Peer Review” section of this document) for each algorithm that they developed\\n* Ensures the Design goals – Performance, Modularity, Reliability, Maintainability, Reusability – are met\\n* This would typically be the PHC Imaging Data Scientist developing the algorithm\\nPeer Reviewer\\n* Responsible for code review and overall algorithm performance verification\\n* Reproducibility of results\\n* Responsible for demonstrating compliance with the peer review requirement (i.e. adding a note in the README file confirming the completion of this process; details on this step are defined in the preceding “Peer Review” section of this document)\\n* This would typically be a PHC Imaging Data Scientist (has to be a resource different from the algorithm developer) within the same product team\\n10. References\\n1. Project Q\\n* Good-ML-Practices-and-Code-Quality-for-Imaging-Team-v0.1.1: Summary and background\\n2. Stage 0 Framework (Ophtha. PHC Program & PHC DS Imaging, with help of Slalom Consultants)\\n3. PHC IX Coding Standards document (PL ID 22931586)\\n4. RGITSC Software Development Process - TOP (PL ID 20403924)\\n5. AI/ML Guidance document for computer system validation of ML systems', metadata={'source': '/Users/alexanderarefolov/Dropbox/Coding_Projects/knowledge_retrieval_LLM_chatbot/knowledge_retrieval_LLM_chatbot/temp/tmppx1_5_2g'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the text using RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1024, chunk_overlap = 80)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an embedding model from AzureOpenAI\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model='text-embedding-3-small', \n",
    "    dimensions=1536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an in-memory Chroma vector store using the provided text chunks \n",
    "# and the embedding model \n",
    "vector_store = Chroma.from_documents(documents = chunks, embedding = embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x1353dcb90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the Azure LLM\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),  \n",
    "    model = os.getenv(\"OPENAI_DEPLOYMENT_NAME\"), \n",
    "    temperature=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1353d7d90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x135349690>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure vector store to act as a retriever (finding similar items, returning top 5)\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a memory buffer to track the conversation\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build messages\n",
    "system_template = r'''\n",
    "You are answering questions only concerning the provided content of the input document.  \n",
    "If you are asked a question that is not related to the document you response will be:\n",
    "'The question is not relevant to the domain of interest'.\n",
    "---------------\n",
    "Context: ```{context}```\n",
    "'''\n",
    "\n",
    "user_template = '''\n",
    "Answer questions only concerning the provided content of the input document.  \n",
    "If you are asked a question that is not related to the document you response will be:\n",
    "'The question is not relevant to the domain of interest'. \n",
    "Here is the user's question: ```{question}```\n",
    "'''\n",
    "\n",
    "messages= [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(user_template)\n",
    "    ]\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=\"\\nYou are answering questions only concerning the provided content of the input document.  \\nIf you are asked a question that is not related to the document you response will be:\\n'The question is not relevant to the domain of interest'.\\n---------------\\nContext: ```{context}```\\n\")), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"\\nAnswer questions only concerning the provided content of the input document.  \\nIf you are asked a question that is not related to the document you response will be:\\n'The question is not relevant to the domain of interest'. \\nHere is the user's question: ```{question}```\\n\"))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up conversational retrieval chain\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm = llm,\n",
    "    retriever = retriever,\n",
    "    memory = memory,\n",
    "    chain_type = 'stuff',\n",
    "    combine_docs_chain_kwargs = {'prompt': qa_prompt },\n",
    "    verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question_file = \"questions_list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answering question 1: What does TOP stand for?\n",
      "\n",
      "Answer to question 1: \n",
      "\n",
      "TOP stands for Technical Operating Procedure as mentioned in the document. \n",
      "\n",
      "Answering question 2: What kind of algorithms does it apply to?\n",
      "\n",
      "Answer to question 2: \n",
      "\n",
      "The TOP (Technical Operating Procedure) applies to rule-based and Machine Learning (ML) based algorithms delivered within the PHC Imaging group. \n",
      "\n",
      "Answering question 3: What are the phases of the development life cycle?\n",
      "\n",
      "Answer to question 3: \n",
      "\n",
      "The phases of the development life cycle outlined in the document are:\n",
      "1. Initialization & preparation\n",
      "2. Development/Experimental phase\n",
      "3. Qualification Phase\n",
      "4. Deployment Phase \n",
      "\n",
      "Answering question 4: What is their number?\n",
      "\n",
      "Answer to question 4: \n",
      "\n",
      "There are four phases outlined in the development life cycle as described in the document. \n",
      "\n",
      "Answering question 5: Give me a recipe for an omelet\n",
      "\n",
      "Answer to question 5: \n",
      "\n",
      "The question is not relevant to the domain of interest. \n",
      "\n",
      "Answering question 6: What are coding standards?\n",
      "Answer to question 6: \n",
      "\n",
      "Coding standards are a series of recommendations and mandates for a specific programming language that determine the programming style, procedures, and methods for various aspects of the program written in that language. They are considered a critical attribute of algorithm development, ensuring consistency, quality, efficiency, and ease of maintenance in the codebase. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# process the input_question_file line by line\n",
    "with open(input_question_file, 'r') as file:\n",
    "    question_counter = 0\n",
    "    for line in file:\n",
    "        question_counter += 1\n",
    "        # Process each line\n",
    "        new_user_question = line\n",
    "        response = answer_question(q = new_user_question, chain = crc)\n",
    "        # print the questiom\n",
    "        print(f\"Answering question {question_counter}: {new_user_question}\")\n",
    "        # print the response\n",
    "        print(f\"Answer to question {question_counter}: \\n\")\n",
    "        print(response, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
